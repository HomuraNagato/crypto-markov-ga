{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bitcoin sentiment analysis using Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generation\n",
    "\n",
    "searchtweets API reference: https://twitterdev.github.io/search-tweets-python/  \n",
    "Twitter API reference: https://developer.twitter.com/en/docs/tweets/search/api-reference/premium-search.html  \n",
    "Twitter tweet object and dictionary: https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/tweet-object  \n",
    "\n",
    "`~/.twitter_keys` contains endpoint, consumer_key, and consumer_secret  \n",
    "Change `yaml_key` to get data for the last 30 days (250 queries / month) or since Twitters inception - 2006 (50 queries / month)  \n",
    "`yaml_key = \"search_tweets_premium_30day\"`  \n",
    "`yaml_key = \"search_tweets_premium_archive\"`:  \n",
    "\n",
    "\n",
    "Each stream increments query  \n",
    "For example, if `results_per_call` is 100 and `max_results` is 1000, that is 10 queries  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from searchtweets import ResultStream, gen_rule_payload, load_credentials, collect_results\n",
    "\n",
    "# general imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import tweepy\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "import time\n",
    "\n",
    "# plotting and visualization\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grabbing bearer token from OAUTH\n"
     ]
    }
   ],
   "source": [
    "premium_search_args = load_credentials(\"~/.twitter_keys.yaml\",\n",
    "                                          yaml_key=\"search_tweets_premium_30day\",\n",
    "                                          env_overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dates\n",
    "months = np.arange(1,13)\n",
    "days = np.arange(1,32)\n",
    "time = [\" 00:00\", \" 03:00\", \" 6:00\", \" 09:00\", \" 12:00\", \" 15:00\", \" 18:00\", \" 21:00\"]\n",
    "dates = []\n",
    "dates_extra = [ \"2018-\" + str(m) + \"-\" + str(d) + str(t) for m in months for d in days for t in time ]\n",
    "spurious_dates = ['2018-2-29', '2018-2-30', '2018-2-31', '2018-4-31', '2018-6-31', '2018-9-31', '2018-11-31']\n",
    "spurious_dates = [ d + t for d in spurious_dates for t in time ]\n",
    "dates = [d for d in dates_extra if d not in spurious_dates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[print(i, d) for i, d in enumerate(dates)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collecting from 2018-9-5 21:00 to 2018-9-15 21:00\n"
     ]
    }
   ],
   "source": [
    "# 1944 2018-9-1 00:00\n",
    "# 2063 2018-9-15 21:00\n",
    "test_dates = dates[1984-1:2063+1]\n",
    "print(\"collecting from\", test_dates[0], \"to\", test_dates[-1], \"in 3 hour intervals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "S2_dict = {}\n",
    "def collect_tweets(from_date, to_date):\n",
    "    # maxResults is capped at 100 for sandbox account\n",
    "    # date format: YYYY-mm-DD HH:MM\n",
    "    bitcoin_rule = gen_rule_payload(\"bitcoin\", results_per_call=100, from_date=from_date, to_date=to_date) \n",
    "    print(bitcoin_rule)\n",
    "    tweets = collect_results(bitcoin_rule, max_results=100, result_stream_args=premium_search_args)\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"query\": \"bitcoin\", \"maxResults\": 100, \"toDate\": \"201809032100\", \"fromDate\": \"201809031800\"}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for i in range(0,len(test_dates[:-1])):\n",
    "    #S2_dict[i] = collect_tweets(test_dates[i], test_dates[i+1])\n",
    "    tweets = np.append(tweets, collect_tweets(test_dates[i], test_dates[i+1]))\n",
    "    if i % 8 == 0 and i != 0:\n",
    "        print(\"waiting 60 seconds\")\n",
    "        time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 Fri Aug 31 23:59:57 +0000 2018 Fri Aug 31 23:57:03 +0000 2018\n"
     ]
    }
   ],
   "source": [
    "print(len(tweets), tweets[0]['created_at'], tweets[-1]['created_at'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### counts and limitations\n",
    "\n",
    "A trial to collect all tweets containing the string 'bitcoin' from the current date until a max number of tweets=1000 reached was 15 minutes. If the max number of tweets is increased, we will eventually go back in time to 30 days. To capture more data beyond this time, Full archive will need to be used. However, with only 50 requests per month, very finely specified dates to remain under 50 requests will need to be identified. I.E. once a month we can collect 25,000 tweets for the last 30 days or 5,000 for some time period earlier than that. For full archive to collect as many as montly, requires subscription of $225/month. Thousands to get over a million tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pandas df from tweets\n",
    "S2 = pd.DataFrame(data=[tweet.text for tweet in tweets], columns=['Tweets'])\n",
    "S2['Date'] = [tweet['created_at'] for tweet in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @helexcorp: Our Public ICO is finished, tha...</td>\n",
       "      <td>Mon Sep 03 20:59:59 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @coinbundlecom: With Bitcoin down, which to...</td>\n",
       "      <td>Mon Sep 03 20:59:58 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is the hype of blockchain starting to cool? An...</td>\n",
       "      <td>Mon Sep 03 20:59:52 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @patestevao: I'm finally starting a new inf...</td>\n",
       "      <td>Mon Sep 03 20:59:52 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#Bitcoin has a difficult task ahead - regardin...</td>\n",
       "      <td>Mon Sep 03 20:59:43 +0000 2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets  \\\n",
       "0  RT @helexcorp: Our Public ICO is finished, tha...   \n",
       "1  RT @coinbundlecom: With Bitcoin down, which to...   \n",
       "2  Is the hype of blockchain starting to cool? An...   \n",
       "3  RT @patestevao: I'm finally starting a new inf...   \n",
       "4  #Bitcoin has a difficult task ahead - regardin...   \n",
       "\n",
       "                             Date  \n",
       "0  Mon Sep 03 20:59:59 +0000 2018  \n",
       "1  Mon Sep 03 20:59:58 +0000 2018  \n",
       "2  Mon Sep 03 20:59:52 +0000 2018  \n",
       "3  Mon Sep 03 20:59:52 +0000 2018  \n",
       "4  Mon Sep 03 20:59:43 +0000 2018  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(tweet):\n",
    "    '''\n",
    "    Utility function to clean the text in a tweet by removing \n",
    "    links and special characters using regex.\n",
    "    '''\n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
    "\n",
    "def analize_sentiment(tweet):\n",
    "    '''\n",
    "    Utility function to classify the polarity of a tweet\n",
    "    using textblob.\n",
    "    \n",
    "    textblob already has a trained analyser to work \n",
    "    with different machine learning models on \n",
    "    natural language processing.\n",
    "    \n",
    "    Might want to train our own model\n",
    "    '''\n",
    "    analysis = TextBlob(clean_tweet(tweet))\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return 1\n",
    "    elif analysis.sentiment.polarity == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "\n",
    "def sentiment_analysis(S2):\n",
    "    # We create a column with the result of the analysis:\n",
    "    S2['SA'] = np.array([ analize_sentiment(tweet) for tweet in S2['Tweets'] ])\n",
    "    \n",
    "    # We construct lists with classified tweets:\n",
    "    pos_tweets = [ tweet for index, tweet in enumerate(S2['Tweets']) if S2['SA'][index] > 0]\n",
    "    neu_tweets = [ tweet for index, tweet in enumerate(S2['Tweets']) if S2['SA'][index] == 0]\n",
    "    neg_tweets = [ tweet for index, tweet in enumerate(S2['Tweets']) if S2['SA'][index] < 0]\n",
    "\n",
    "    # We print percentages:\n",
    "    print(\"Percentage of positive tweets: {}%\".format(len(pos_tweets)*100/len(S2['Tweets'])))\n",
    "    print(\"Percentage of neutral tweets: {}%\".format(len(neu_tweets)*100/len(S2['Tweets'])))\n",
    "    print(\"Percentage de negative tweets: {}%\".format(len(neg_tweets)*100/len(S2['Tweets'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of positive tweets: 37.037974683544306%\n",
      "Percentage of neutral tweets: 52.32911392405063%\n",
      "Percentage de negative tweets: 10.632911392405063%\n"
     ]
    }
   ],
   "source": [
    "sentiment_analysis(S2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "S2['Tweets'].to_csv('tweets_2018-09-03-21_Tweets.csv', index=False)\n",
    "S2['Date'].to_csv('tweets_2018-09-03-21_Date.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to rate limitations, not all data was able to be gathered at once and resulted in gaps in data. Running through the dates and re-collecting the data allowed for a continuous data collection from September 01-15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sep 01-00:00\n",
    "S3_Date_0901A = pd.read_csv('tweets_2018-09-01-00_Date.csv', names=['Date'])\n",
    "S3_Tweets_0901A = pd.read_csv('tweets_2018-09-01-00_Tweets.csv', names=['Tweets'])\n",
    "# Sep 01-03\n",
    "S3_Date_090103 = pd.read_csv('tweets_2018-09-01_2018-09-03_Date.csv', names=['Date'])\n",
    "S3_Tweets_090103 = pd.read_csv('tweets_2018-09-01_2018-09-03_Tweets.csv', names=['Tweets'])\n",
    "# Sep 03-21:00\n",
    "S3_Date_0903A = pd.read_csv('tweets_2018-09-03-21_Date.csv', names=['Date'])\n",
    "S3_Tweets_0903A = pd.read_csv('tweets_2018-09-03-21_Tweets.csv', names=['Tweets'])\n",
    "# Sep 03-05\n",
    "S3_Date_090305 = pd.read_csv('tweets_2018-09-03_2018-09-05_Date.csv', names=['Date'])\n",
    "S3_Tweets_090305 = pd.read_csv('tweets_2018-09-03_2018-09-05_Tweets.csv', names=['Tweets'])\n",
    "# Sep 15-21:00\n",
    "S3_Date_0915A = pd.read_csv('tweets_2018-09-15-21_Date.csv', names=['Date'])\n",
    "S3_Tweets_0915A = pd.read_csv('tweets_2018-09-15-21_Tweets.csv', names=['Tweets'])\n",
    "# Sep 06-15\n",
    "S3_Date_090615 = pd.read_csv('tweets_2018-09-06_2018-09-15_Date.csv', names=['Date'])\n",
    "S3_Tweets_090615 = pd.read_csv('tweets_2018-09-06_2018-09-15_Tweets.csv', names=['Tweets'])\n",
    "\n",
    "S3_A = pd.concat([S3_Tweets_0901A, S3_Date_0901A], axis=1)\n",
    "S3_B = pd.concat([S3_Tweets_090103, S3_Date_090103], axis=1)\n",
    "S3_C = pd.concat([S3_Tweets_0903A, S3_Date_0903A], axis=1)\n",
    "S3_D = pd.concat([S3_Tweets_090305, S3_Date_090305], axis=1)\n",
    "S3_E = pd.concat([S3_Tweets_0915A, S3_Date_0915A], axis=1)\n",
    "S3_F = pd.concat([S3_Tweets_090615, S3_Date_090615], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Tweets  \\\n",
      "0  Haha @Eminem dropped that new album and name d...   \n",
      "1  RT @coingecko: Have you tried comparing coins ...   \n",
      "2  RT @cryptocomicon: Chris DeRose spends an 86 m...   \n",
      "3  RT @santisiri: un partido polÃ­tico que opera s...   \n",
      "4  RT @BitcoinDood: DNA: The Safest Way to Store ...   \n",
      "\n",
      "                             Date  \n",
      "0  Fri Aug 31 23:59:57 +0000 2018  \n",
      "1  Fri Aug 31 23:59:51 +0000 2018  \n",
      "2  Fri Aug 31 23:59:47 +0000 2018  \n",
      "3  Fri Aug 31 23:59:46 +0000 2018  \n",
      "4  Fri Aug 31 23:59:45 +0000 2018   \n",
      "                                               Tweets  \\\n",
      "0  https://t.co/yLZluuYevy DECENTRALISED ENERGY P...   \n",
      "1  ðŸ“‰ Biggest Losers (1 hr) ðŸ“‰\\nNoah Coin $NOAH -3....   \n",
      "2  Crypto News: Yahoo! Worldâ€™s Sixth-Most Popular...   \n",
      "3  RT @coingecko: Have you tried comparing coins ...   \n",
      "4  Bitcoin Gets Awareness Boost From Mention On E...   \n",
      "\n",
      "                             Date  \n",
      "0  Sat Sep 01 02:59:59 +0000 2018  \n",
      "1  Sat Sep 01 02:59:58 +0000 2018  \n",
      "2  Sat Sep 01 02:59:54 +0000 2018  \n",
      "3  Sat Sep 01 02:59:54 +0000 2018  \n",
      "4  Sat Sep 01 02:59:53 +0000 2018   \n",
      "                                               Tweets  \\\n",
      "0  RT @helexcorp: Our Public ICO is finished, tha...   \n",
      "1  RT @coinbundlecom: With Bitcoin down, which to...   \n",
      "2  Is the hype of blockchain starting to cool? An...   \n",
      "3  RT @patestevao: I'm finally starting a new inf...   \n",
      "4  #Bitcoin has a difficult task ahead - regardin...   \n",
      "\n",
      "                             Date  \n",
      "0  Mon Sep 03 20:59:59 +0000 2018  \n",
      "1  Mon Sep 03 20:59:58 +0000 2018  \n",
      "2  Mon Sep 03 20:59:52 +0000 2018  \n",
      "3  Mon Sep 03 20:59:52 +0000 2018  \n",
      "4  Mon Sep 03 20:59:43 +0000 2018   \n",
      "                                               Tweets  \\\n",
      "0  RT @stakecube: ðŸŽHUGE BITCOIN W SPECTRUM GIVEAW...   \n",
      "1  @bitcoin_token @CoinDeal_ @Wolves @Stitcherako...   \n",
      "2  RT @Autobayio: A little weekend treat Autobaye...   \n",
      "3  RT @LovetronMajor: https://t.co/nNbdIo7uBU #mu...   \n",
      "4  @_M_o_z_a @_tm3k i think most of it is trollin...   \n",
      "\n",
      "                             Date  \n",
      "0  Mon Sep 03 23:59:57 +0000 2018  \n",
      "1  Mon Sep 03 23:59:54 +0000 2018  \n",
      "2  Mon Sep 03 23:59:51 +0000 2018  \n",
      "3  Mon Sep 03 23:59:48 +0000 2018  \n",
      "4  Mon Sep 03 23:59:47 +0000 2018   \n",
      "                                               Tweets  \\\n",
      "0  Bitcoin Price Intraday Analysis: BTC/USD Break...   \n",
      "1  ðŸ”„ Prices update in $EUR (1 hour):\\n\\n$BTC - 57...   \n",
      "2  Alibaba Responsible for 10% of World's Blockch...   \n",
      "3  RT @Monarchtoken: Watch out for an amazing par...   \n",
      "4  RT @CNBCFastMoney: Goldman Sachs is reportedly...   \n",
      "\n",
      "                             Date  \n",
      "0  Wed Sep 05 23:59:58 +0000 2018  \n",
      "1  Wed Sep 05 23:59:57 +0000 2018  \n",
      "2  Wed Sep 05 23:59:56 +0000 2018  \n",
      "3  Wed Sep 05 23:59:46 +0000 2018  \n",
      "4  Wed Sep 05 23:59:45 +0000 2018   \n",
      "                                               Tweets  \\\n",
      "0  Buy/Sell Bitcoin changes with up to 100x Lever...   \n",
      "1  Free and Best Automatic Bitcoin - Altcoins - U...   \n",
      "2  RT @CryptoMoe81: $Bitcoin idea \"14,XX% Drop\" -...   \n",
      "3  Check out this awesome site! You can COPY pro ...   \n",
      "4  RT @APompliano: So many people are cheering ag...   \n",
      "\n",
      "                             Date  \n",
      "0  Thu Sep 06 02:59:59 +0000 2018  \n",
      "1  Thu Sep 06 02:59:57 +0000 2018  \n",
      "2  Thu Sep 06 02:59:56 +0000 2018  \n",
      "3  Thu Sep 06 02:59:54 +0000 2018  \n",
      "4  Thu Sep 06 02:59:53 +0000 2018  \n"
     ]
    }
   ],
   "source": [
    "print(S3_A.head(), '\\n', S3_B.head(), '\\n', S3_C.head(), '\\n', S3_D.head(), '\\n', S3_E.head(), '\\n', S3_F.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "S3 = pd.concat([S3_A, S3_B, S3_C, S3_D, S3_E, S3_F], axis=0)\n",
    "S3['Date'].to_csv('tweets_2018-08-01_2018-08-15_Date.csv', index=False)\n",
    "S3['Tweets'].to_csv('tweets_2018-08-01_2018-08-15_Tweets.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Haha @Eminem dropped that new album and name d...</td>\n",
       "      <td>Fri Aug 31 23:59:57 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @coingecko: Have you tried comparing coins ...</td>\n",
       "      <td>Fri Aug 31 23:59:51 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @cryptocomicon: Chris DeRose spends an 86 m...</td>\n",
       "      <td>Fri Aug 31 23:59:47 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @santisiri: un partido polÃ­tico que opera s...</td>\n",
       "      <td>Fri Aug 31 23:59:46 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @BitcoinDood: DNA: The Safest Way to Store ...</td>\n",
       "      <td>Fri Aug 31 23:59:45 +0000 2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets  \\\n",
       "0  Haha @Eminem dropped that new album and name d...   \n",
       "1  RT @coingecko: Have you tried comparing coins ...   \n",
       "2  RT @cryptocomicon: Chris DeRose spends an 86 m...   \n",
       "3  RT @santisiri: un partido polÃ­tico que opera s...   \n",
       "4  RT @BitcoinDood: DNA: The Safest Way to Store ...   \n",
       "\n",
       "                             Date  \n",
       "0  Fri Aug 31 23:59:57 +0000 2018  \n",
       "1  Fri Aug 31 23:59:51 +0000 2018  \n",
       "2  Fri Aug 31 23:59:47 +0000 2018  \n",
       "3  Fri Aug 31 23:59:46 +0000 2018  \n",
       "4  Fri Aug 31 23:59:45 +0000 2018  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7895</th>\n",
       "      <td>RT @bitcoincardvd: You can start your Bitcoin ...</td>\n",
       "      <td>Sat Sep 15 20:57:43 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7896</th>\n",
       "      <td>RT @securixio: We at https://t.co/3OqG6HXwB0 p...</td>\n",
       "      <td>Sat Sep 15 20:57:40 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7897</th>\n",
       "      <td>It doesnâ€™t matter if Bitcoin is $6k or $50k.\\n...</td>\n",
       "      <td>Sat Sep 15 20:57:39 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7898</th>\n",
       "      <td>RT @iMariaJohnsen: Uncovering facts on #blockc...</td>\n",
       "      <td>Sat Sep 15 20:57:37 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7899</th>\n",
       "      <td>RT @favycoin: Grab your #Favycoin and don't mi...</td>\n",
       "      <td>Sat Sep 15 20:57:33 +0000 2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Tweets  \\\n",
       "7895  RT @bitcoincardvd: You can start your Bitcoin ...   \n",
       "7896  RT @securixio: We at https://t.co/3OqG6HXwB0 p...   \n",
       "7897  It doesnâ€™t matter if Bitcoin is $6k or $50k.\\n...   \n",
       "7898  RT @iMariaJohnsen: Uncovering facts on #blockc...   \n",
       "7899  RT @favycoin: Grab your #Favycoin and don't mi...   \n",
       "\n",
       "                                Date  \n",
       "7895  Sat Sep 15 20:57:43 +0000 2018  \n",
       "7896  Sat Sep 15 20:57:40 +0000 2018  \n",
       "7897  Sat Sep 15 20:57:39 +0000 2018  \n",
       "7898  Sat Sep 15 20:57:37 +0000 2018  \n",
       "7899  Sat Sep 15 20:57:33 +0000 2018  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S3.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary so far\n",
    "\n",
    "It's reasonable to assume that twitter data is more interesting when viewed as a larger picture than a collection centered around a pinpoint. To do this, subsamples of twitter data need to be gathered for a range of days. Tweets starting and ending on the dates listed below are gathered. The from_date is the listed day and the to_date is set to the next day. However rate limits will terminate early after 100 tweets have been gathered for that day, so typically only a couple minutes of tweets per day per every three hours. This method of collection 100 tweets per day is an efficient method to collect a fraction twitter data over a larger number of days. \n",
    "\n",
    "- 1944 2018-9-1 00:00\n",
    "- 2063 2018-9-15 21:00\n",
    " \n",
    "Sentiment analysis follows the preformulated TextBlob sentiment ML scoring algorithm. The data is then stored in a dataframe called S2 and written to individual csvs (due to texts containing commas as well, rather than fight it, just keep it separate) to paste back into a dataframe for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
